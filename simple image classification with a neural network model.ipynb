{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "719/719 [==============================] - 31s 42ms/step - loss: 0.6865 - accuracy: 0.5644 - val_loss: 0.6589 - val_accuracy: 0.5970\n",
      "Epoch 2/10\n",
      "719/719 [==============================] - 27s 37ms/step - loss: 0.6583 - accuracy: 0.6055 - val_loss: 0.6477 - val_accuracy: 0.6120\n",
      "Epoch 3/10\n",
      "719/719 [==============================] - 27s 37ms/step - loss: 0.6509 - accuracy: 0.6169 - val_loss: 0.6408 - val_accuracy: 0.6220\n",
      "Epoch 4/10\n",
      "719/719 [==============================] - 30s 42ms/step - loss: 0.6459 - accuracy: 0.6222 - val_loss: 0.6380 - val_accuracy: 0.6295\n",
      "Epoch 5/10\n",
      "719/719 [==============================] - 29s 40ms/step - loss: 0.6399 - accuracy: 0.6278 - val_loss: 0.6492 - val_accuracy: 0.6120\n",
      "Epoch 6/10\n",
      "719/719 [==============================] - 29s 40ms/step - loss: 0.6337 - accuracy: 0.6347 - val_loss: 0.6351 - val_accuracy: 0.6315\n",
      "Epoch 7/10\n",
      "719/719 [==============================] - 30s 41ms/step - loss: 0.6280 - accuracy: 0.6397 - val_loss: 0.6316 - val_accuracy: 0.6275\n",
      "Epoch 8/10\n",
      "719/719 [==============================] - 28s 40ms/step - loss: 0.6240 - accuracy: 0.6445 - val_loss: 0.6307 - val_accuracy: 0.6330\n",
      "Epoch 9/10\n",
      "719/719 [==============================] - 28s 39ms/step - loss: 0.6218 - accuracy: 0.6451 - val_loss: 0.6479 - val_accuracy: 0.6270\n",
      "Epoch 10/10\n",
      "719/719 [==============================] - 29s 40ms/step - loss: 0.6179 - accuracy: 0.6514 - val_loss: 0.6289 - val_accuracy: 0.6335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7241bda90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths to your train and validation directories\n",
    "train_dir = r\"C:\\Users\\abhij\\Downloads\\dogscats\\train\"\n",
    "validation_dir = r\"C:\\Users\\abhij\\Downloads\\dogscats\\valid\"\n",
    "\n",
    "# Define image data generators for train and validation datasets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values to [0, 1]\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow images from directories and generate batches of augmented data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(28, 28),        # Resize images to 28x28\n",
    "    batch_size=32,               # Set batch size\n",
    "    class_mode='categorical'     # Specify class mode as categorical since we have multiple classes\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(28, 28),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28, 3]),  # Input shape is 28x28x3 (RGB images)\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(60, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # Output layer with 2 neurons (cats and dogs) and softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "The model predicts that the image contains a cat.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(r\"C:\\Users\\abhij\\Downloads\\dogscats\\test1\\10035.jpg\")  # Replace \"example_image.jpg\" with the path to your image\n",
    "image = image.resize((28, 28))  # Resize the image to match the input shape expected by the model\n",
    "image = np.array(image) / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "# Add batch dimension and convert to float32\n",
    "input_image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Get the predicted class (0 for cat, 1 for dog)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "if predicted_class == 0:\n",
    "    print(\"The model predicts that the image contains a cat.\")\n",
    "else:\n",
    "    print(\"The model predicts that the image contains a dog.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
